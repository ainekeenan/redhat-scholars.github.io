= Introduction to OpenShift Service Registry
include::_attributes.adoc[]

Learn how to use OpenShift Service Registry to manage your Apache Kafka schemas without having to install, configure, run, and maintain infrastructure.


image::openshift-streams-logo.png[OpenShift Streams logo,200,float="right"]

*Tutorial*: link:https://redhat-scholars.github.io/managed-kafka-service-registry-workshop/[https://redhat-scholars.github.io/managed-kafka-service-registry-workshop/,window=_blank]

{nbsp} +

[#one]
== Introduction to OpenShift Streams for Apache Kafka

[cols="1,3,2"]  
|===
| *Duration* | *Audience* | *Level*
|1 hour
|Java developers that want to manage schemas for their applications that connect to Apache Kafka.
|Intermediate
|===

Kafka itself does not mandate a format for messages. Popular formats for Kafka messages include JSON, Protobuf and Avro. Avro and Protobuf are binary formats, which are much more compact than for example JSON. They require less storage space and less bandwidth. On the other hand, Avro and protobuf require a schema to serialize and deserialize the binary payload. These schemas are generally stored and maintained in a schema registry.

OpenShift Service Registry is a managed cloud service which provides you with an instance of a schema registry, where you can store and manage different kind of schemas, including OpenAPI spec documents and Avro and Protobuf schemas.

In this tutorial you will:

* Provision a Kafka instance using OpenShift Streams for Apache Kafka.
* Provision a Service Registry instance using OpenShift Service Registry.
* Create a service account to connect to the Kafka and the Service Registry instances.
* Run a couple of Quarkus applications which produce and consume messages to and from the Kafka instance using the Avro binary format. The Avro schema is stored in the Service Registry instance.

